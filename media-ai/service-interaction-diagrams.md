# Media AI Service Interaction Diagrams

**Visual documentation of the Media AI service interactions, AI processing workflows, and system architecture using Mermaid diagrams.**

## Service Integration Overview

### Complete AI Processing Event Flow

```mermaid
graph TD
    subgraph "External Services"
        GCS[â˜ï¸ Google Cloud Storage<br/>Photo Repository]
        OpenAI[ğŸ¤– OpenAI GPT-4 Vision<br/>AI Analysis API]
        Redis[ğŸ—„ï¸ Redis<br/>Cache Layer]
    end

    subgraph "Event Bus (Kafka)"
        PostCreated[ğŸ“¨ post.created]
        PostEnhanced[ğŸ“¨ post.enhanced]
        ProcessingError[ğŸ“¨ processing.error]
    end

    subgraph "fn-posts Domain"
        Posts[ğŸ“ Posts Service]
        PhotoUpload[ğŸ“¸ Photo Upload Handler]
    end

    subgraph "fn-media-ai Domain"
        KafkaConsumer[ğŸ“¡ Kafka Consumer]
        EventHandler[âš¡ Post Created Handler]
        AIController[ğŸ§  AI Processing Controller]

        subgraph "AI Pipeline"
            PhotoDownloader[ğŸ“¥ Photo Downloader]
            ObjectDetector[ğŸ‘ï¸ Object Detection]
            SceneClassifier[ğŸï¸ Scene Classification]
            OCRExtractor[ğŸ“ OCR Text Extraction]
            LocationInferrer[ğŸ“ Location Inference]
            MetadataCombiner[ğŸ”„ Metadata Combiner]
        end

        EventPublisher[ğŸ“¤ Event Publisher]
        CacheManager[ğŸ—ƒï¸ Cache Manager]
    end

    subgraph "Downstream Services"
        PostsUpdate[ğŸ“ fn-posts<br/>Enhancement Updates]
        Matcher[ğŸ¯ fn-matcher<br/>Enhanced Matching]
        Notifications[ğŸ“§ fn-notifications<br/>Processing Updates]
    end

    Posts --> PhotoUpload
    PhotoUpload --> GCS
    Posts --> PostCreated
    PostCreated --> KafkaConsumer
    KafkaConsumer --> EventHandler
    EventHandler --> AIController

    AIController --> PhotoDownloader
    PhotoDownloader --> GCS
    PhotoDownloader --> ObjectDetector
    ObjectDetector --> SceneClassifier
    SceneClassifier --> OCRExtractor
    OCRExtractor --> LocationInferrer
    LocationInferrer --> OpenAI
    LocationInferrer --> MetadataCombiner

    MetadataCombiner --> CacheManager
    CacheManager --> Redis
    MetadataCombiner --> EventPublisher
    EventPublisher --> PostEnhanced
    EventPublisher --> ProcessingError

    PostEnhanced --> PostsUpdate
    PostEnhanced --> Matcher
    PostEnhanced --> Notifications
```

## AI Processing Pipeline Architecture

### Multi-Model AI Processing Workflow

```mermaid
graph TD
    subgraph "Input Processing"
        A[ğŸ“¨ PostCreated Event] --> B[ğŸ“‹ Event Validation]
        B --> C[ğŸ” Photo URL Extraction]
        C --> D[ğŸ“¥ Photo Download from GCS]
    end

    subgraph "Parallel AI Model Processing"
        D --> E1[ğŸ¯ YOLO Object Detection]
        D --> E2[ğŸï¸ ResNet Scene Classification]
        D --> E3[ğŸ“ Tesseract OCR]
        D --> E4[ğŸ¤– GPT-4 Vision Analysis]

        E1 --> F1[ğŸ“¦ Objects & Attributes]
        E2 --> F2[ğŸŒ Scene Context]
        E3 --> F3[ğŸ“„ Text & Labels]
        E4 --> F4[ğŸ“ Location Context]
    end

    subgraph "Result Processing"
        F1 --> G[ğŸ”„ Metadata Combiner]
        F2 --> G
        F3 --> G
        F4 --> G

        G --> H[ğŸ“Š Confidence Evaluator]
        H --> I{Confidence Level?}

        I -->|â‰¥85%| J[âœ… Auto-Enhance]
        I -->|70-84%| K[ğŸ’¡ Suggest Tags]
        I -->|50-69%| L[ğŸ‘€ Human Review]
        I -->|<50%| M[ğŸ—‘ï¸ Discard]

        J --> N[ğŸ“¤ Publish Enhancement]
        K --> N
        L --> N
    end

    subgraph "Output Events"
        N --> O[ğŸ“¨ post.enhanced Event]
        M --> P[ğŸ“¨ processing.error Event]
    end

    style E1 fill:#ff9999
    style E2 fill:#99ccff
    style E3 fill:#99ff99
    style E4 fill:#ffcc99
```

## Confidence-Based Enhancement Flow

### Enhancement Level Decision Tree

```mermaid
graph TD
    A[ğŸ§  AI Analysis Complete] --> B[ğŸ“Š Calculate Overall Confidence]
    B --> C{Confidence Score}

    C -->|â‰¥ 0.85| D[ğŸš€ Auto-Enhancement]
    C -->|0.70 - 0.84| E[ğŸ’­ Suggestion Mode]
    C -->|0.50 - 0.69| F[ğŸ‘€ Human Review Required]
    C -->|< 0.50| G[ğŸ—‘ï¸ Discard Results]

    D --> D1[ğŸ“ Update Post Automatically]
    D --> D2[ğŸ·ï¸ Add High-Confidence Tags]
    D --> D3[ğŸ“„ Enhance Description]
    D --> D4[ğŸ“¤ Publish Enhancement Event]

    E --> E1[ğŸ’¡ Generate Tag Suggestions]
    E --> E2[ğŸ“‹ Create Review Queue Entry]
    E --> E3[ğŸ“§ Notify User for Approval]

    F --> F1[ğŸ” Flag for Manual Review]
    F --> F2[ğŸ‘¨â€ğŸ’¼ Add to Admin Queue]
    F --> F3[ğŸ“Š Track for Model Training]

    G --> G1[ğŸ“ Log Low Confidence Result]
    G --> G2[ğŸ—ƒï¸ Store for Analytics Only]

    D4 --> H[ğŸ“¨ Event: post.enhanced]
    E3 --> I[ğŸ“¨ Event: tags.suggested]
    F2 --> J[ğŸ“¨ Event: review.required]
    G2 --> K[ğŸ“¨ Event: processing.completed]

    style D fill:#90EE90
    style E fill:#FFE4B5
    style F fill:#FFA07A
    style G fill:#D3D3D3
```

## Event Processing Sequence

### PostCreated to PostEnhanced Flow

```mermaid
sequenceDiagram
    participant P as fn-posts
    participant K as Kafka
    participant MA as fn-media-ai
    participant GCS as Google Cloud Storage
    participant AI as AI Models
    participant R as Redis Cache
    participant N as fn-notifications

    P->>K: Publish post.created event
    Note over P,K: Event contains post data<br/>and photo URLs

    K->>MA: Consume post.created event
    MA->>MA: Validate event structure

    loop For each photo
        MA->>GCS: Download photo
        GCS->>MA: Return photo data

        par Parallel AI Processing
            MA->>AI: Object detection (YOLO)
            MA->>AI: Scene classification (ResNet)
            MA->>AI: OCR extraction (Tesseract)
            MA->>AI: Location inference (GPT-4V)
        end

        AI->>MA: Return analysis results
    end

    MA->>MA: Combine & evaluate confidence

    alt High Confidence (â‰¥85%)
        MA->>R: Cache enhancement results
        MA->>K: Publish post.enhanced event
        K->>P: Enhancement applied automatically
        K->>N: Notify user of enhancement

    else Medium Confidence (70-84%)
        MA->>R: Cache suggestions
        MA->>K: Publish tags.suggested event
        K->>P: Create suggestion queue entry
        K->>N: Notify user for approval

    else Low Confidence (50-69%)
        MA->>K: Publish review.required event
        K->>P: Flag for manual review

    else Very Low Confidence (<50%)
        MA->>MA: Log and discard results
        MA->>K: Publish processing.completed event
    end
```

## Error Handling and Retry Patterns

### Error Recovery Workflow

```mermaid
graph TD
    A[ğŸ“¨ PostCreated Event] --> B[âš¡ Event Processing]
    B --> C{Processing Success?}

    C -->|âœ… Success| D[ğŸ“¤ Publish Enhancement]
    C -->|âŒ Error| E[ğŸ” Error Classification]

    E --> F{Error Type}

    F -->|Photo Download| G[ğŸ“¥ Download Error Handler]
    F -->|AI Model| H[ğŸ§  Model Error Handler]
    F -->|API Rate Limit| I[â±ï¸ Rate Limit Handler]
    F -->|Network| J[ğŸŒ Network Error Handler]
    F -->|Unknown| K[â“ Generic Error Handler]

    G --> G1[ğŸ”„ Retry with Backoff]
    G1 --> G2{Max Retries?}
    G2 -->|No| G3[â° Exponential Backoff]
    G3 --> B
    G2 -->|Yes| L[ğŸ’€ Dead Letter Queue]

    H --> H1[ğŸ”„ Fallback Model]
    H1 --> H2{Fallback Success?}
    H2 -->|Yes| D
    H2 -->|No| M[ğŸ“ Partial Results]

    I --> I1[â³ Wait for Rate Limit Reset]
    I1 --> I2[ğŸ”„ Retry Request]
    I2 --> B

    J --> J1[ğŸ”„ Circuit Breaker Check]
    J1 --> J2{Circuit Open?}
    J2 -->|Closed| J3[ğŸ”„ Retry Immediately]
    J2 -->|Open| J4[â° Wait for Circuit Reset]
    J3 --> B
    J4 --> B

    K --> K1[ğŸ“ Log Unknown Error]
    K1 --> L

    L --> N[ğŸ“¨ Publish Error Event]
    M --> O[ğŸ“¨ Publish Partial Enhancement]

    style G fill:#FFB6C1
    style H fill:#DDA0DD
    style I fill:#F0E68C
    style J fill:#98FB98
    style K fill:#FFA07A
```

## Cache Strategy and Data Flow

### Redis Caching Architecture

```mermaid
graph TD
    subgraph "Cache Layers"
        L1[ğŸš€ L1: Model Weights<br/>TTL: 24h]
        L2[âš¡ L2: AI Results<br/>TTL: 1h]
        L3[ğŸ“Š L3: Photo Metadata<br/>TTL: 30m]
        L4[ğŸ” L4: Analysis Queue<br/>TTL: 5m]
    end

    subgraph "AI Processing Flow"
        A[ğŸ“¸ Photo Processing Request] --> B{Check L3 Cache}
        B -->|Hit| C[ğŸ“Š Return Cached Metadata]
        B -->|Miss| D[ğŸ§  Start AI Analysis]

        D --> E{Check L1 Cache}
        E -->|Hit| F[âš¡ Load Cached Models]
        E -->|Miss| G[ğŸ“¥ Download Model Weights]
        G --> H[ğŸ’¾ Cache in L1]
        H --> F

        F --> I[ğŸ” Run AI Inference]
        I --> J{Check L2 Cache}
        J -->|Hit| K[ğŸ“‹ Combine with Cached Results]
        J -->|Miss| L[ğŸ§® Complete Analysis]

        L --> M[ğŸ’¾ Cache Results in L2]
        M --> N[ğŸ’¾ Cache Metadata in L3]
        N --> O[ğŸ“¤ Return Enhanced Data]

        K --> O
        C --> O
    end

    subgraph "Cache Management"
        P[ğŸ”„ Cache Invalidation] --> Q{Invalidation Type}
        Q -->|Model Update| R[ğŸ—‘ï¸ Clear L1 Cache]
        Q -->|Data Change| S[ğŸ—‘ï¸ Clear L2 & L3]
        Q -->|Manual| T[ğŸ—‘ï¸ Clear All Caches]

        U[ğŸ“Š Cache Monitoring] --> V[ğŸ“ˆ Hit Rate Metrics]
        V --> W[ğŸ¯ Optimize Cache TTL]
    end

    style L1 fill:#FF6B6B
    style L2 fill:#4ECDC4
    style L3 fill:#45B7D1
    style L4 fill:#96CEB4
```

## Model Performance and Monitoring

### AI Model Metrics Dashboard

```mermaid
graph TD
    subgraph "Model Performance Tracking"
        A[ğŸ“Š Model Metrics Collector] --> B[ğŸ¯ YOLO Performance]
        A --> C[ğŸï¸ ResNet Performance]
        A --> D[ğŸ“ OCR Performance]
        A --> E[ğŸ¤– GPT-4V Performance]

        B --> B1[â±ï¸ Inference Time: 1.2s avg]
        B --> B2[ğŸ¯ Accuracy: 92%]
        B --> B3[ğŸ’¾ Memory Usage: 512MB]

        C --> C1[â±ï¸ Inference Time: 0.8s avg]
        C --> C2[ğŸ¯ Accuracy: 88%]
        C --> C3[ğŸ’¾ Memory Usage: 256MB]

        D --> D1[â±ï¸ Inference Time: 0.6s avg]
        D --> D2[ğŸ¯ Accuracy: 94%]
        D --> D3[ğŸ’¾ Memory Usage: 128MB]

        E --> E1[â±ï¸ API Call Time: 2.1s avg]
        E --> E2[ğŸ¯ Accuracy: 89%]
        E --> E3[ğŸ’° Token Usage: 150/req]
    end

    subgraph "Performance Monitoring"
        F[ğŸ“ˆ Prometheus Metrics] --> G[ğŸ” Grafana Dashboards]
        G --> H[âš ï¸ Alert Rules]

        H --> I{Performance Threshold}
        I -->|Latency > 5s| J[ğŸš¨ High Latency Alert]
        I -->|Accuracy < 80%| K[ğŸ“‰ Low Accuracy Alert]
        I -->|Memory > 2GB| L[ğŸ’¾ High Memory Alert]
        I -->|Error Rate > 5%| M[âŒ High Error Alert]

        J --> N[ğŸ“§ Notify DevOps Team]
        K --> O[ğŸ”§ Trigger Model Retraining]
        L --> P[ğŸ“ˆ Scale Resources]
        M --> Q[ğŸ” Investigate Error Causes]
    end

    subgraph "Model Optimization Loop"
        R[ğŸ“Š Performance Analysis] --> S[ğŸ¯ Identify Bottlenecks]
        S --> T[ğŸ”§ Optimization Strategy]
        T --> U[âš¡ Apply Optimizations]
        U --> V[ğŸ“ Measure Improvements]
        V --> R
    end

    style B fill:#FF9999
    style C fill:#99CCFF
    style D fill:#99FF99
    style E fill:#FFCC99
```

## Integration with External Services

### External API Interaction Flow

```mermaid
graph LR
    subgraph "fn-media-ai Service"
        A[ğŸ§  AI Controller] --> B[ğŸ“¡ External API Manager]
        B --> C[ğŸ”§ Circuit Breaker]
        C --> D[â±ï¸ Rate Limiter]
        D --> E[ğŸ”„ Retry Handler]
    end

    subgraph "External APIs"
        F[ğŸ¤– OpenAI GPT-4 Vision]
        G[â˜ï¸ Google Cloud Storage]
        H[ğŸ” Google Vision API]
        I[ğŸ·ï¸ AWS Rekognition]
    end

    subgraph "API Management Patterns"
        J[ğŸ“Š API Health Monitor]
        K[ğŸ“ˆ Usage Tracker]
        L[ğŸ’° Cost Monitor]
        M[ğŸš¦ Fallback Manager]
    end

    E --> F
    E --> G
    E --> H
    E --> I

    F --> J
    G --> J
    H --> J
    I --> J

    J --> K
    K --> L
    L --> M

    M --> N{API Healthy?}
    N -->|Yes| O[âœ… Use Primary API]
    N -->|No| P[ğŸ”„ Use Fallback API]

    O --> Q[ğŸ“Š Log Success Metrics]
    P --> R[âš ï¸ Log Fallback Usage]

    style F fill:#FF6B6B
    style G fill:#4ECDC4
    style H fill:#45B7D1
    style I fill:#96CEB4
```

## Scalability and Load Distribution

### Horizontal Scaling Architecture

```mermaid
graph TD
    subgraph "Load Balancer"
        LB[âš–ï¸ Load Balancer<br/>Round Robin]
    end

    subgraph "fn-media-ai Replicas"
        A1[ğŸ§  AI Worker 1<br/>GPU Enabled]
        A2[ğŸ§  AI Worker 2<br/>CPU Only]
        A3[ğŸ§  AI Worker 3<br/>GPU Enabled]
        A4[ğŸ§  AI Worker N<br/>Auto-scaled]
    end

    subgraph "Processing Distribution"
        B[ğŸ“‹ Task Queue] --> C{Task Type}
        C -->|Heavy AI| D[ğŸš€ GPU Workers]
        C -->|Light Processing| E[âš¡ CPU Workers]
        C -->|Batch Jobs| F[ğŸ“¦ Batch Processors]
    end

    subgraph "Resource Allocation"
        G[ğŸ“Š Resource Monitor] --> H{Load Level}
        H -->|High| I[ğŸ“ˆ Scale Up]
        H -->|Normal| J[â¡ï¸ Maintain]
        H -->|Low| K[ğŸ“‰ Scale Down]

        I --> L[ğŸ”„ Add Replicas]
        K --> M[ğŸ—‘ï¸ Remove Replicas]
    end

    LB --> A1
    LB --> A2
    LB --> A3
    LB --> A4

    A1 --> B
    A2 --> B
    A3 --> B
    A4 --> B

    D --> A1
    D --> A3
    E --> A2
    F --> A4

    style A1 fill:#FF6B6B
    style A2 fill:#4ECDC4
    style A3 fill:#FF6B6B
    style A4 fill:#96CEB4
```

## Development and Testing Workflow

### CI/CD Pipeline Integration

```mermaid
graph TD
    subgraph "Development Cycle"
        A[ğŸ‘¨â€ğŸ’» Developer Commit] --> B[ğŸ”§ Pre-commit Hooks]
        B --> C[ğŸ“¤ Push to Repository]
        C --> D[ğŸš€ CI/CD Triggered]
    end

    subgraph "Automated Testing"
        D --> E[ğŸ§ª Unit Tests]
        E --> F[ğŸ¤– AI Model Tests]
        F --> G[ğŸ”— Integration Tests]
        G --> H[ğŸ“Š Performance Tests]
        H --> I[ğŸ”’ Security Scans]
    end

    subgraph "Model Validation"
        F --> F1[ğŸ¯ Accuracy Validation]
        F --> F2[â±ï¸ Latency Testing]
        F --> F3[ğŸ’¾ Memory Profiling]
        F --> F4[ğŸ”„ Regression Testing]
    end

    subgraph "Deployment Pipeline"
        I --> J{All Tests Pass?}
        J -->|Yes| K[ğŸ—ï¸ Build Docker Image]
        J -->|No| L[âŒ Fail Pipeline]

        K --> M[ğŸ”’ Security Scan Image]
        M --> N[ğŸ“¤ Push to Registry]
        N --> O[ğŸš€ Deploy to Staging]
        O --> P[ğŸ§ª Staging Tests]
        P --> Q[âœ… Deploy to Production]

        L --> R[ğŸ“§ Notify Developers]
    end

    subgraph "Monitoring & Feedback"
        Q --> S[ğŸ“Š Production Monitoring]
        S --> T[ğŸ“ˆ Performance Metrics]
        T --> U[ğŸ”„ Feedback Loop]
        U --> A
    end

    style F1 fill:#90EE90
    style F2 fill:#FFE4B5
    style F3 fill:#FFA07A
    style F4 fill:#D3D3D3
```

## Real-time Processing Dashboard

### Live Metrics Visualization

```mermaid
graph TD
    subgraph "Real-time Metrics Dashboard"
        A[ğŸ“Š Live Metrics Collector] --> B[ğŸ“ˆ Processing Rate]
        A --> C[â±ï¸ Average Latency]
        A --> D[ğŸ“Š Confidence Distribution]
        A --> E[ğŸ¯ Model Accuracy]
        A --> F[ğŸ’° API Costs]

        B --> B1[ğŸ“ˆ 150 photos/min]
        C --> C1[â±ï¸ 3.2s average]
        D --> D1[ğŸ“Š 85% high confidence]
        E --> E1[ğŸ¯ 91% accuracy]
        F --> F1[ğŸ’° $24.50/hour]
    end

    subgraph "Alert System"
        G[ğŸš¨ Alert Manager] --> H{Threshold Check}
        H -->|Latency > 5s| I[âš ï¸ Performance Alert]
        H -->|Accuracy < 85%| J[ğŸ“‰ Quality Alert]
        H -->|Cost > $50/h| K[ğŸ’° Budget Alert]
        H -->|Queue > 100| L[ğŸ“ˆ Backlog Alert]

        I --> M[ğŸ“± SMS to On-call]
        J --> N[ğŸ“§ Email to ML Team]
        K --> O[ğŸ’¬ Slack to Finance]
        L --> P[ğŸ“ Page DevOps]
    end

    subgraph "Auto-scaling Triggers"
        Q[ğŸ“Š Resource Monitor] --> R{Resource Usage}
        R -->|CPU > 80%| S[ğŸ“ˆ Scale Up Pods]
        R -->|Memory > 2GB| T[ğŸ’¾ Add Memory]
        R -->|Queue > 50| U[ğŸ”„ Add Workers]
        R -->|Cost > $40/h| V[ğŸ¯ Optimize Models]

        S --> W[â• +2 Replicas]
        T --> X[ğŸ“¦ Request More Memory]
        U --> Y[ğŸ”„ Horizontal Scale]
        V --> Z[âš¡ Use Smaller Models]
    end

    style B1 fill:#90EE90
    style C1 fill:#FFE4B5
    style D1 fill:#87CEEB
    style E1 fill:#DDA0DD
    style F1 fill:#F0E68C
```

---

*These diagrams provide a comprehensive visual overview of the fn-media-ai service architecture, processing flows, and system interactions. For architectural details, see [domain-architecture.md](domain-architecture.md). For API specifications, see [api-documentation.md](api-documentation.md). For deployment instructions, see [deployment-guide.md](deployment-guide.md).*